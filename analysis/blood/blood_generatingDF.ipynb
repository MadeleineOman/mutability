{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0eea42a-7597-4403-85b8-e6d41e3051c8",
   "metadata": {},
   "source": [
    "# **Lets create the big dataframe for blood**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194936ca-adae-48be-ac5b-7338c1b48d52",
   "metadata": {},
   "source": [
    "**strucutre of this notebook :**\n",
    "1. **Blood sites on blood data**\n",
    "    - 1.1 imports \n",
    "    - 1.2 get all mutant sites \n",
    "    - 1.3 append non-mut sites --> no overlap with mutant sites (takes 20mins) \n",
    "    - 1.4 basic declarations for the loop --> nte that still not using all tracks (ie hapmap ) \n",
    "    - 1.5 diagnostics (Xed out for script: was an interactive chunk) \n",
    "    - 1.6 big daddy loop \n",
    "    - 1.7 loop print error lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "918fd279-9312-48c8-bacd-c811b46f106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnase_file = \"data/blood/track_data/DNAse/wgEncodeUwDnaseSeqRawSignalRep1Gm12878.bed.gz\"\n",
    "h3k27ac_file = \"data/blood/track_data/H3k27/wgEncodeBroadChipSeqSignalGm12878H3k27ac.bed.gz\"\n",
    "h3k4me1_file = \"data/blood/track_data/H3k4me1/wgEncodeBroadChipSeqSignalGm12878H3k4me1.bed.gz\"\n",
    "h3k4me3_file = \"data/blood/track_data/H3k4me3/wgEncodeBroadChipSeqSignalGm12878H3k4me3.bed.gz\"\n",
    "# methylationCHG_file = \"bgzip  data/blood/track_data/methylation/methylation_CHG.bed.gz\"\n",
    "# methylationCHH_file = \"bgzip data/blood/track_data/methylation/methylation_CHH.bed.gz\"\n",
    "# methylationCpG_file = \"bgzip data/blood/track_data/methylation/methylation_CpG.bed.g\n",
    "laminB1_file = \"data/global/track_data/laminB1/hg18.laminB1.bed.gz\"\n",
    "recombination_file = \"data/global/track_data/recombination/recombination.bed.gz\"\n",
    "repeats_file = \"data/global/track_data/repeats/repeats.bed.gz\"\n",
    "replication_file = \"data/global/track_data/replication/replication.bed.gz\"\n",
    "# phastcons_fileLoc = \"data/global/track_data/phastcons/\"\n",
    "\n",
    "#dictionry where i specify which col contains the information in the datafile , 0 indexed \n",
    "tracksColFile_dict = {\"H3k27\":[4,\"../../data/blood/track_data/H3k27/wgEncodeBroadChipSeqSignalGm12878H3k27ac.bed.gz\"], \n",
    "                      \"H3k4me1\":[4,\"../../data/blood/track_data/H3k4me1/wgEncodeBroadChipSeqSignalGm12878H3k4me1.bed.gz\"], \n",
    "                       \"H3k4me3\":[4,\"../../data/blood/track_data/H3k4me3/wgEncodeBroadChipSeqSignalGm12878H3k4me3.bed.gz\"], \n",
    "                      \"DNAse\":[4,\"../../data/blood/track_data/DNAse/wgEncodeUwDnaseSeqRawSignalRep1Gm12878.bed.gz\"], \n",
    "                      \"laminB1\":[4,\"../../data/global/track_data/laminB1/hg18.laminB1.bed.gz\"], \n",
    "                      \"recombination\": [4,\"../../data/global/track_data/recombination/recombination.bed.gz\"],\n",
    "                       \"Repeats\":[\"binary\", \"../../data/global/track_data/repeats/repeats.bed.gz\"],\n",
    "                      \"Replication\":[3,\"../../data/global/track_data/replication/replication.bed.gz\"]} #remove nucmec/dennis, phastcons, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad7d49-62f6-4601-b532-d01fdadab142",
   "metadata": {},
   "source": [
    "## **1.1 imports** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b5c0562-d081-4ea0-9c74-ac4d7cd878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from numpy.random import choice\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from Bio import AlignIO\n",
    "import pysam \n",
    "from tqdm import tqdm \n",
    "from datetime import datetime\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f9d68-40fc-48e9-bdca-7adb26220912",
   "metadata": {},
   "source": [
    "## **1.2  mutant sites list** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f1013b5-f35b-4a7e-bd41-35595411c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_lines = open('../../data/blood/mutations/blood_mutations_hg18_sorted_tabdelim.bed').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "162e52f1-d205-4411-a830-cc39597db316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr1\\t1212518\\t1212519\\tID_1_individual_2_single-cell_1\\tC\\tT\\t0.59\\tSCNN1D\\texon\\tY=>Y\\t-\\thuman\\tfemale\\t39\\tblood(hematopoietic_stem/progenitor_cells,HSPCs)\\twhole_genome_sequencing(single-stem-cell_clonal_culture)\\tbone_marrow_mononuclear_cells\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutations_lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61e7aa8-66eb-4d06-b5a5-0be8bf8830af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387   non chrN muts (ommited) from these lables: ['chr17_random' 'chr21_random' 'chrX' 'chrY']\n",
      "number included mutations = 8776\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary where each chrom key will have a n empty list  \n",
    "muts_bychrom_dict = {}\n",
    "for x in range(1,23): \n",
    "    key_string = 'chr{n}'.format(n=x)\n",
    "    muts_bychrom_dict[key_string] = []\n",
    "    \n",
    "#fill each chromosome's empty list  with the sites for that chrom \n",
    "non_chrnMuts = []#create list of chrom names that dont belong to chrN format --> disgnostic \n",
    "for x in range(1,len(mutations_lines)): \n",
    "    chrom_mut = mutations_lines[x].split()[0]\n",
    "    mut_startSite = mutations_lines[x].split()[1]\n",
    "    if chrom_mut in muts_bychrom_dict.keys():                  #controlling for chrX/chrY\n",
    "        muts_bychrom_dict[chrom_mut].append(mut_startSite)\n",
    "    else: \n",
    "        non_chrnMuts.append(chrom_mut)\n",
    "\n",
    "        \n",
    "#testing making usre the only sites that dont make it are sex chromosome mutations \n",
    "print(len(non_chrnMuts),\"  non chrN muts (ommited) from these lables:\", np.unique(non_chrnMuts))\n",
    "\n",
    "#add the sites infro from file \n",
    "sites = []#sites = list of sites \n",
    "for chrom_key in muts_bychrom_dict.keys(): \n",
    "    for mutation_element in muts_bychrom_dict[chrom_key]: \n",
    "        sites.append([chrom_key, int(mutation_element),1]) #the 1 is for mutation status column. 1 = yes \n",
    "        \n",
    "print(\"number included mutations = \" +str(len(sites)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ff569-69c5-4cfd-b157-82e3cfe85dd4",
   "metadata": {},
   "source": [
    "## **1.3 append non-mutations to sites list** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a77826-a8f9-4991-ba0d-5a33180d3796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8776/8776 [00:01<00:00, 6469.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#get chrom length information so I can perform weighted choice for non-mut site selection \n",
    "ChromLengths = pd.read_csv('../../data/global/sequence/hg38_chromosomelengths.csv') #read in the csv file of hg38 chrom lengths I found on the internets \n",
    "total_length=0 #lets sum (get the total length) \n",
    "for length in list(ChromLengths.Length): \n",
    "    total_length+=int(length.replace(\",\",\"\"))\n",
    "\n",
    "#build dictionary to store porbability \n",
    "dict_lengths = {}#creat emepty dictionary \n",
    "for x in range (0,22): \n",
    "        tmp_index = x +1\n",
    "        length = str(ChromLengths[x:x+1]).split()[4]\n",
    "        length = length.replace(\",\", \"\")\n",
    "        length = int(length)\n",
    "        dict_lengths[\"chr\"+str(tmp_index)] = length\n",
    "\n",
    "#make the porbability of choosing a chrom based on length \n",
    "list_0chroms = ['chr01', 'chr02', 'chr03','chr04','chr05','chr06','chr07','chr08','chr09','chr10','chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19','chr20','chr21','chr22']\n",
    "list_chroms = ['chr' + str(i) for i in range(1, 23)]\n",
    "list_chrom_probabilities = []\n",
    "for chrom in list_chroms: \n",
    "    list_chrom_probabilities.append(dict_lengths[chrom]/total_length)\n",
    "\n",
    "#maing sure the probability list sums to one (arbitrarily add the rounding error to chr1)\n",
    "list_chrom_probabilities[0] = list_chrom_probabilities[0]+1-sum(list_chrom_probabilities) # adds the 0.00000001 left from rounding errors to the chr1 so sum adds perfectly to 1. \n",
    "assert(sum(list_chrom_probabilities)==1)\n",
    "\n",
    "#perfrom the non-mutant site draw \n",
    "number_nonmuts = len(sites)\n",
    "chrom_draw = choice(list_chroms, number_nonmuts,p=list_chrom_probabilities)\n",
    "\n",
    "#visualize the draw: \n",
    "#print(collections.Counter(draw))\n",
    "\n",
    "#make the sites list with the chr# and site \n",
    "for chrom in tqdm(chrom_draw): \n",
    "    site_draw = random.randrange(1,dict_lengths[chrom])\n",
    "    if [chrom,site_draw] not in sites: \n",
    "        sites.append([chrom,site_draw,0]) # the 0 if for the mutation status column. 0 = no \n",
    "# print(len(sites))\n",
    "#haha there was one mutation overlap!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7667a-1f32-4c09-973d-0a6e90cf4b52",
   "metadata": {},
   "source": [
    "## **1.4 basic declarations for the loop** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd867cc7-3a77-487e-92f0-906b1bd9dc96",
   "metadata": {},
   "source": [
    "**tissue specific declarations (may chnage b/t somatic models )** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0d77bff-496b-4764-b363-43c3e6afea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_df = pd.read_table('../../data/blood/mutations/blood_mutations_hg18_sorted_tabdelim.bed', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b86c7b37-696e-4659-b653-1ecee602f905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rename header for easier access down the line \n",
    "#replace space with underscore, / with Or, and Age(yars) with AgeInYears\n",
    "mutations_df.columns = ['chromosome',  'start',  'fake_end', 'file_ID',  'Reference_allele', 'Variant_allele', 'VAF', 'Gene_name', 'Region',\n",
    " 'AA', 'COSMIC', 'Species', 'Gender', 'Age(years)', 'Tissue/Cell_type', 'Single-cell_genomics_biotechnology/Method', 'Control_sample/tissue']\n",
    "\n",
    "\n",
    "mutations_list = mutations_df.start.values.tolist()  # may need to chnage the name ofwhich coloumn has the mutations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9d465-c2ab-4cc9-8c39-dd62bf170450",
   "metadata": {},
   "source": [
    "**declarations that should stay the same for all tissues** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9bc833e9-fe6c-4bef-b253-f317cda6d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic declarations (constants) \n",
    "list_tissueSpecific_tracks = [\"Transcription\", \"DNAse\", \"H3k4me1\", \"H3k4me3\", \"H3k27\"]\n",
    "\n",
    "row =[] #final product that gets printed to file (after str conversion)\n",
    "\n",
    "alignment_discordant = []                                    #used to collect all the instances where the hg18 fasta result doesnt match the mutation dataset \"Ref\" column \n",
    "tracks_NA_is_zero = [\"Transcription\", \"laminB1\", \"Repeats\", \"H3k4me1\", \"H3k4me3\", \"H3k27\", \"DNAse\"] #remove nucmec/dennis\n",
    "list_no_seq_at_site = []\n",
    "list_sites_outOfBufferRange = []\n",
    "\n",
    "fastas_dict = {}   # creating dictionary with fasta alignment, length of seq, \n",
    "for chrom in list_chroms:\n",
    "    filename_tmp = \"../../data/global/sequence/{c}.fa.gz\".format(c=chrom)\n",
    "    fastas_dict[chrom] = []\n",
    "    with gzip.open(filename_tmp, \"rt\") as handle:\n",
    "        fastas_dict[chrom].append(AlignIO.read(handle,\"fasta\"))\n",
    "        alignment_tmp = fastas_dict[chrom][0]\n",
    "        fastas_dict[chrom].append(len(str(alignment_tmp[0].seq)))\n",
    "\n",
    "\n",
    "#variable declaration  \n",
    "list_of_surrounding_contexts = [0,100,10000] #note if you chnagee/ increase this, then you oncrese the buffer zone (not using sites in the buffer, len(dna)-max_distance )\n",
    "distance_max = max(list_of_surrounding_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da038f0-9337-497d-99f4-edd4617d7e88",
   "metadata": {},
   "source": [
    "# **1.6 big daddy loop** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427933d-40d9-440b-a870-b5768fff807b",
   "metadata": {},
   "source": [
    "**table creation notes** \n",
    "1. no overlapping non-muts sites \n",
    "2. sites are picked allover the genome (ind of buffer) but then sites outside buffer excluded from table \n",
    "    - can keep track of sites in \"list_sites_outOfBufferrange\n",
    "3. if the site was mutant, then triplet centre base chnages (not good!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4cd5ee-578f-4d66-a9e6-9a8060a9b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                  | 1132/17552 [18:21<4:23:42,  1.04it/s]"
     ]
    }
   ],
   "source": [
    "#code: \n",
    "timestamp = datetime.now().strftime(\"%Y/%m/%d\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "with open('../../data/blood/predictorDf_{t}_updatedTriplet.txt'.format(t=timestamp), 'w') as f:                                                    # opening line to write to a file \n",
    "    \n",
    "    header = \"Chromosome\"+ \"\\t\"+\"site\"+\"\\t\" +\"triplet\"+\"\\t\"+\"mutation_status\"                        # creating the begining of the header \n",
    "    for trackname in tracksColFile_dict.keys():                                                     # the rest of the header is a function of tracks \n",
    "        for distance in list_of_surrounding_contexts:                                                # and distance (need a col for every track and for every distance value within ) \n",
    "            header = header + \"\\t\"+str(trackname)+\"-\"+str(distance)\n",
    "    for distance in list_of_surrounding_contexts:                                                    # creating the end of the header assoc with no track (the seqeunce at different \n",
    "        header = header + \"\\t\"+\"Apercent-\"+str(distance)+ \"\\t\"+\"Gpercent-\"+str(distance)+ \"\\t\"+\"Cpercent-\"+str(distance)+ \"\\t\"+\"Tpercent-\"+str(distance)   # distace values) \n",
    "    header = header +\"\\n\"                                                                            # obviously needs to end with a \\n \n",
    "    f.write(header)                                                                                  #write header to file \n",
    "\n",
    "    \n",
    "    for site in tqdm(sites): \n",
    "        if site[1] <= distance_max or site[1]+distance_max >= fastas_dict[site[0]][1]:               # only use sites that will have values for site +- max distance (buffer). second element in fastas dict is the length \n",
    "            list_sites_outOfBufferRange.append(site)\n",
    "        \n",
    "        else: \n",
    "            row = []\n",
    "            row.extend([site[0], site[1]])\n",
    "            alignment = fastas_dict[site[0]][0]                                                       #create the alingment from the list of fastas \n",
    "            \n",
    "            \n",
    "            #makes the triplet depending on itf mutant or nah \n",
    "            if site[2] ==1:                                     #muts_by-chrom_dict is literally a dictionary containing list of sites that are mutations in that chrom. \n",
    "                mutation_row = mutations_df[(mutations_df.chromosome == site[0]) & (mutations_df.start == site[1])]  #get the row containing mut info out of the df \n",
    "\n",
    "                mutation_bp = mutation_row.Variant_allele.values[0]\n",
    "                mutated_triplet = str(alignment[0,site[1]-1])+str(mutation_bp)+str(alignment[0,site[1]+1]).upper()\n",
    "\n",
    "                old_bp = mutation_row.Reference_allele.values[0]\n",
    "                old_triplet = str(alignment[0,site[1]-1])+str(old_bp)+str(alignment[0,site[1]+1]).upper()\n",
    "\n",
    "                row.extend([mutated_triplet, 1])\n",
    "\n",
    "                seq_triplet = str(alignment[0,site[1]-1:site[1]+2].seq)\n",
    "                if old_triplet.upper() != seq_triplet.upper(): \n",
    "                    alignment_discordant.append(old_triplet+\" \"+str(mutation_row)+\" \"+str(sites.index(site))+\" \"+str(site))\n",
    "                    \n",
    "            else: \n",
    "                triplet= str(alignment[0,site[1]-1:site[1]+2].seq).upper()\n",
    "                row.extend([triplet,0])\n",
    "            \n",
    "            #converting fro 0 to nomral chrom lists so can get correct files \n",
    "#             index_chromConversion = list_chroms.index(site[0])                                        #takes the first element of site (chr from tabix) and searches for the index within the list. \n",
    "#             chrom_forFiles = list_0chroms[index_chromConversion]                                      #used the previous index to get out the ch 0 number needed for the files : chr01 \n",
    "\n",
    "            #track stuff \n",
    "            for trackname,track_val in tracksColFile_dict.items():                 \n",
    "                \n",
    "                filename = track_val[1]                   \n",
    "                    \n",
    "                for distance in list_of_surrounding_contexts: \n",
    "                    #track_output = [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]\n",
    "                    if not [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]:                #if no value at that site \n",
    "                        if trackname in tracks_NA_is_zero: \n",
    "                            row.append(0)\n",
    "                        else: \n",
    "                            row.extend([\"NA\"])                                                                                      \n",
    "\n",
    "                    else:                                                   \n",
    "                        track_output = [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]\n",
    "                        multiple_values = []\n",
    "                        if tracksColFile_dict[trackname][0] == 4:\n",
    "                            for element in track_output: \n",
    "                                multiple_values.append(float(element.split()[4]))\n",
    "                            #print(multiple_values)\n",
    "                            average_value = sum(multiple_values)/len(multiple_values) \n",
    "                            row.append(average_value)\n",
    "                        elif tracksColFile_dict[trackname][0] == 3: \n",
    "                            for element in track_output: \n",
    "                                multiple_values.append(float(element.split()[3]))\n",
    "                            #print(multiple_values)\n",
    "                            average_value = sum(multiple_values)/len(multiple_values) \n",
    "                            row.append(average_value)\n",
    "                        elif tracksColFile_dict[trackname][0] == 'binary': \n",
    "                            row.append(len(track_output))\n",
    "                        else: \n",
    "                            print(\"ERROR: track coloumns not 4 or 5 or binary\")\n",
    "                            print(tracksColFile_dict[trackname])\n",
    "\n",
    "            #sequence stuff                \n",
    "            for distance in list_of_surrounding_contexts: \n",
    "                seq_around = str(alignment[0,site[1]-1:site[1]+1+1].seq)\n",
    "                if seq_around != '': \n",
    "                    seq_around = str(alignment[0,site[1]-distance:site[1]+distance+1].seq)\n",
    "                    Acount = seq_around.count('a')+seq_around.count(\"A\")\n",
    "                    Gcount = seq_around.count('g')+seq_around.count(\"G\")\n",
    "                    Ccount = seq_around.count('c')+seq_around.count(\"C\")\n",
    "                    Tcount = seq_around.count('t')+seq_around.count(\"T\")\n",
    "                    Apercent = Acount/len(seq_around)\n",
    "                    Gpercent = Gcount/len(seq_around)\n",
    "                    Cpercent = Ccount/len(seq_around)\n",
    "                    Tpercent = Tcount/len(seq_around)\n",
    "                    row.extend([Apercent, Gpercent, Cpercent, Tpercent])\n",
    "                else: \n",
    "                    row.extend(['NA','NA','NA','NA'])\n",
    "                    list_no_seq_at_site.append(site)\n",
    "            #print(header\n",
    "            #print(row)          \n",
    "            #print(len(row))\n",
    "            row_string = str()\n",
    "            for i in range(0,len(row)): \n",
    "                row_string = row_string+str(row[i])+\"\\t\"\n",
    "            row_string = row_string.rstrip(\"\\t\")\n",
    "            row_string = row_string+\"\\n\"\n",
    "            f.write(row_string)\n",
    "print(len(list_sites_outOfBufferRange))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591bca6-0432-4fc0-a34f-0371ff298321",
   "metadata": {},
   "source": [
    "## ** 1.7 printing error output of the model ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e7a2ef0-7f5b-4d5f-a606-3b45f98db491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "6602\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(list_sites_outOfBufferRange))\n",
    "print(len(alignment_discordant))\n",
    "print(len( list_no_seq_at_site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79d835-0a57-4e0d-bfb0-7139327d8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "93aad073-5fc0-4f14-9157-0a54f706accc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3761394712853236"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alignment_discordant)/len(sites)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mutability] *",
   "language": "python",
   "name": "conda-env-.conda-mutability-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
