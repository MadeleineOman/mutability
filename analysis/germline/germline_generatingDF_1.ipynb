{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0eea42a-7597-4403-85b8-e6d41e3051c8",
   "metadata": {},
   "source": [
    "# **Lets create the big dataframe for blood**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194936ca-adae-48be-ac5b-7338c1b48d52",
   "metadata": {},
   "source": [
    "**strucutre of this notebook :**\n",
    "1. **Blood sites on blood data**\n",
    "    - 1.1 imports \n",
    "    - 1.2 get all mutant sites \n",
    "    - 1.3 append non-mut sites --> no overlap with mutant sites (takes 20mins) \n",
    "    - 1.4 basic declarations for the loop --> nte that still not using all tracks (ie hapmap ) \n",
    "    - 1.5 diagnostics (Xed out for script: was an interactive chunk) \n",
    "    - 1.6 big daddy loop \n",
    "    - 1.7 loop print error lists "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad7d49-62f6-4601-b532-d01fdadab142",
   "metadata": {},
   "source": [
    "## **1.1 imports** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5c0562-d081-4ea0-9c74-ac4d7cd878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from numpy.random import choice\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from Bio import AlignIO\n",
    "import pysam \n",
    "from tqdm import tqdm \n",
    "from datetime import datetime\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f9d68-40fc-48e9-bdca-7adb26220912",
   "metadata": {},
   "source": [
    "## **1.2  mutant sites list** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1013b5-f35b-4a7e-bd41-35595411c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_lines = open('../../data/germline/mutation_data/mutations_hg18_tabDelim.bed').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61e7aa8-66eb-4d06-b5a5-0be8bf8830af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62   non chrN muts (ommited) from these lables: ['chr13_random' 'chr17_random' 'chr19_random' 'chr21_random'\n",
      " 'chr22_random' 'chr4_random' 'chr6_random' 'chr9_random' 'chrX']\n",
      "number included mutations = 104941\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary where each chrom key will have a n empty list \n",
    "duplicate_lines = []\n",
    "muts_bychrom_dict = {}\n",
    "for x in range(1,23): \n",
    "    key_string = 'chr{n}'.format(n=x)\n",
    "    muts_bychrom_dict[key_string] = []\n",
    "    \n",
    "#fill each chromosome's empty list  with the sites for that chrom \n",
    "non_chrnMuts = []#create list of chrom names that dont belong to chrN format --> disgnostic \n",
    "for line in mutations_lines[1:]: \n",
    "    if line[0]==\"c\":                                               #aking sure the line is a chrN (lots of weird junk..) \n",
    "        chrom_mut = line.split(\"\\t\")[0]\n",
    "        mut_startSite = line.split(\"\\t\")[1]                  #getting rid of the weird double(hgopefully) \n",
    "        if chrom_mut in muts_bychrom_dict.keys():                  #controlling for chrX/chrY\n",
    "            if mut_startSite not in muts_bychrom_dict[chrom_mut]: \n",
    "                muts_bychrom_dict[chrom_mut].append(mut_startSite)\n",
    "            else: duplicate_lines.append(line)\n",
    "        else: \n",
    "            non_chrnMuts.append(chrom_mut)\n",
    "\n",
    "        \n",
    "#testing making usre the only sites that dont make it are sex chromosome mutations \n",
    "print(len(non_chrnMuts),\"  non chrN muts (ommited) from these lables:\", np.unique(non_chrnMuts))\n",
    "\n",
    "#add the sites infro from file \n",
    "sites = []#sites = list of sites \n",
    "for chrom_key in muts_bychrom_dict.keys(): \n",
    "    for mutation_element in muts_bychrom_dict[chrom_key]: \n",
    "        \n",
    "        sites.append([chrom_key, int(mutation_element),1]) #the 1 is for mutation status column. 1 = yes \n",
    "        \n",
    "print(\"number included mutations = \" +str(len(sites)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ff569-69c5-4cfd-b157-82e3cfe85dd4",
   "metadata": {},
   "source": [
    "## **1.3 append non-mutations to sites list** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a77826-a8f9-4991-ba0d-5a33180d3796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 104941/104941 [03:00<00:00, 580.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#get chrom length information so I can perform weighted choice for non-mut site selection \n",
    "ChromLengths = pd.read_csv('../../data/global/sequence/hg38_chromosomelengths.csv') #read in the csv file of hg38 chrom lengths I found on the internets \n",
    "total_length=0 #lets sum (get the total length) \n",
    "for length in list(ChromLengths.Length): \n",
    "    total_length+=int(length.replace(\",\",\"\"))\n",
    "\n",
    "#build dictionary to store porbability \n",
    "dict_lengths = {}#creat emepty dictionary \n",
    "for x in range (0,22): \n",
    "        tmp_index = x +1\n",
    "        length = str(ChromLengths[x:x+1]).split()[4]\n",
    "        length = length.replace(\",\", \"\")\n",
    "        length = int(length)\n",
    "        dict_lengths[\"chr\"+str(tmp_index)] = length\n",
    "\n",
    "#make the porbability of choosing a chrom based on length \n",
    "list_0chroms = ['chr01', 'chr02', 'chr03','chr04','chr05','chr06','chr07','chr08','chr09','chr10','chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19','chr20','chr21','chr22']\n",
    "list_chroms = ['chr' + str(i) for i in range(1, 23)]\n",
    "list_chrom_probabilities = []\n",
    "for chrom in list_chroms: \n",
    "    list_chrom_probabilities.append(dict_lengths[chrom]/total_length)\n",
    "\n",
    "#maing sure the probability list sums to one (arbitrarily add the rounding error to chr1)\n",
    "list_chrom_probabilities[0] = list_chrom_probabilities[0]+1-sum(list_chrom_probabilities) # adds the 0.00000001 left from rounding errors to the chr1 so sum adds perfectly to 1. \n",
    "assert(sum(list_chrom_probabilities)==1)\n",
    "\n",
    "#perfrom the non-mutant site draw \n",
    "number_nonmuts = len(sites)\n",
    "chrom_draw = choice(list_chroms, number_nonmuts,p=list_chrom_probabilities)\n",
    "\n",
    "#visualize the draw: \n",
    "#print(collections.Counter(draw))\n",
    "\n",
    "#make the sites list with the chr# and site \n",
    "for chrom in tqdm(chrom_draw): \n",
    "    site_draw = random.randrange(1,dict_lengths[chrom])\n",
    "    if [chrom,site_draw] not in sites: \n",
    "        sites.append([chrom,site_draw,0]) # the 0 if for the mutation status column. 0 = no \n",
    "# print(len(sites))\n",
    "#haha there was one mutation overlap!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7667a-1f32-4c09-973d-0a6e90cf4b52",
   "metadata": {},
   "source": [
    "## **1.4 basic declarations for the loop** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd867cc7-3a77-487e-92f0-906b1bd9dc96",
   "metadata": {},
   "source": [
    "**tissue specific declarations (may chnage b/t somatic models )** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d77bff-496b-4764-b363-43c3e6afea73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mutations_df = pd.read_table('../../data/germline/mutation_data/mutations_hg18_tabDelim.bed', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86c7b37-696e-4659-b653-1ecee602f905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rename header for easier access down the line \n",
    "#replace space with underscore, / with Or, and Age(yars) with AgeInYears\n",
    "mutations_df.columns = [\"chrom\",\"pos\",\"fake_end\",\"ref\",\"alt\",\"Fathers_age_at_conception\",\"Mothers_age_at_conception\"]#this has to chnage if i modify the mutation donwload script \n",
    "\n",
    "mutations_list = mutations_df.pos.values.tolist()  # may need to chnage the name ofwhich coloumn has the mutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9a47e7-b28c-499f-a9d8-97659006b859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>fake_end</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>Fathers_age_at_conception</th>\n",
       "      <th>Mothers_age_at_conception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>544956</td>\n",
       "      <td>544957</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>712003</td>\n",
       "      <td>712004</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>769193</td>\n",
       "      <td>769194</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>814664</td>\n",
       "      <td>814665</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>830494</td>\n",
       "      <td>830495</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom     pos  fake_end ref alt  Fathers_age_at_conception  \\\n",
       "0  chr1  544956    544957   C   T                         39   \n",
       "1  chr1  712003    712004   C   G                         36   \n",
       "2  chr1  769193    769194   A   G                         29   \n",
       "3  chr1  814664    814665   T   G                         34   \n",
       "4  chr1  830494    830495   A   G                         32   \n",
       "\n",
       "   Mothers_age_at_conception  \n",
       "0                         37  \n",
       "1                         30  \n",
       "2                         32  \n",
       "3                         31  \n",
       "4                         21  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9d465-c2ab-4cc9-8c39-dd62bf170450",
   "metadata": {},
   "source": [
    "**declarations that should stay the same for all tissues** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7601afed-ff23-494b-ba09-017e4d8bc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionry where i specify which col contains the information in the datafile , 0 indexed \n",
    "tracksColFile_dict = {\"H3k27_female\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/H3k27/H3k27ac_female_hg18_sorted.bed.gz\"], \n",
    "                      \"H3k27_male\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/H3k27/H3k27ac_male_hg18_sorted.bed.gz\"],\n",
    "                      \"H3k4me1_female\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/H3k4me1/H3k4me1_female_hg18_sorted.bed.gz\"], \n",
    "                      \"H3k4me1_male\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/H3k4me1/H3k4me1_male_hg18_sorted.bed.gz\"], \n",
    "                       \"H3k4me3_female\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/H3k4me3/H3k4me3_female_hg18_sorted.bed.gz\"], \n",
    "                       \"H3k4me3_male\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/H3k4me3/H3k4me3_male_hg18_sorted.bed.gz\"], \n",
    "                      \"DNAse_female\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/DNAse/DNAse_female_hg18_sorted.bed.gz\"], \n",
    "                      \"DNAse_male\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/DNAse/DNAse_male_hg18_sorted.bed.gz\"], \n",
    "                      \"Transcription_male\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/transcription/transcription_male_hg18_sorted.bed.gz\"],\n",
    "                      \"Transcription_female\":[3,\"specific\",\"Na=0\",\"../../data/germline/track_data/transcription/transcription_female_hg18_sorted.bed.gz\"],\n",
    "                                            \n",
    "                      \n",
    "                      \"laminB1\":[4,\"global\",\"Na=0\",\"../../data/global/track_data/laminB1/hg18.laminB1.bed.gz\"], \n",
    "                      \"recombination\": [4,\"global\",\"Na=Na\",\"../../data/global/track_data/recombination/recombination.bed.gz\"],\n",
    "                       \"Repeats\":[\"binary\",\"global\",\"Na=0\", \"../../data/global/track_data/repeats/repeats.bed.gz\"],\n",
    "                      \"Replication\":[3,\"global\",\"Na=0\",\"../../data/global/track_data/replication/replication.bed.gz\"]} #remove nucmec/dennis, phastcons, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc833e9-fe6c-4bef-b253-f317cda6d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:53<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "#basic declarations (constants) \n",
    "\n",
    "fastas_dict = {}   # creating dictionary with fasta alignment, length of seq, \n",
    "for chrom in tqdm(list_chroms):\n",
    "    filename_tmp = \"../../data/global/sequence/{c}.fa.gz\".format(c=chrom)\n",
    "    fastas_dict[chrom] = []\n",
    "    with gzip.open(filename_tmp, \"rt\") as handle:\n",
    "        fastas_dict[chrom].append(AlignIO.read(handle,\"fasta\"))\n",
    "        alignment_tmp = fastas_dict[chrom][0]\n",
    "        fastas_dict[chrom].append(len(str(alignment_tmp[0].seq)))\n",
    "\n",
    "\n",
    "#variable declaration  \n",
    "list_of_surrounding_contexts = [0,100,10000] #note if you chnagee/ increase this, then you oncrese the buffer zone (not using sites in the buffer, len(dna)-max_distance )\n",
    "distance_max = max(list_of_surrounding_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da038f0-9337-497d-99f4-edd4617d7e88",
   "metadata": {},
   "source": [
    "# **1.6 big daddy loop** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427933d-40d9-440b-a870-b5768fff807b",
   "metadata": {},
   "source": [
    "**table creation notes** \n",
    "1. no overlapping non-muts sites \n",
    "2. sites are picked allover the genome (ind of buffer) but then sites outside buffer excluded from table \n",
    "    - can keep track of sites in \"list_sites_outOfBufferrange\n",
    "3. if the site was mutant, then triplet centre base chnages (not good!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4cd5ee-578f-4d66-a9e6-9a8060a9b427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 4/52471 [00:04<17:26:03,  1.20s/it]"
     ]
    }
   ],
   "source": [
    "#nned to be reset every simulation \n",
    "alignment_discordant = []                                    #used to collect all the instances where the hg18 fasta result doesnt match the mutation dataset \"Ref\" column \n",
    "list_no_seq_at_site = []\n",
    "list_sites_outOfBufferRange = []\n",
    "\n",
    "#shorter verison for now \n",
    "sites = sites[int(len(sites)/4):int(len(sites)/2)]\n",
    "\n",
    "#code: \n",
    "timestamp = datetime.now().strftime(\"%Y/%m/%d\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "with open('../../data/germline/dataframes/predictorDF_{t}_1.txt'.format(t=timestamp), 'w') as f:                                                    # opening line to write to a file \n",
    "    \n",
    "    header = \"Chromosome\"+ \"\\t\"+\"site\"+\"\\t\" +\"triplet\"+\"\\t\"+\"mutation_status\"                        # creating the begining of the header \n",
    "    for trackname in tracksColFile_dict.keys():                                                     # the rest of the header is a function of tracks \n",
    "        for distance in list_of_surrounding_contexts:                                                # and distance (need a col for every track and for every distance value within ) \n",
    "            header = header + \"\\t\"+str(trackname)+\"-\"+str(distance)\n",
    "    for distance in list_of_surrounding_contexts:                                                    # creating the end of the header assoc with no track (the seqeunce at different \n",
    "        header = header + \"\\t\"+\"Apercent-\"+str(distance)+ \"\\t\"+\"Gpercent-\"+str(distance)+ \"\\t\"+\"Cpercent-\"+str(distance)+ \"\\t\"+\"Tpercent-\"+str(distance)   # distace values) \n",
    "    header = header +\"\\n\"                                                                            # obviously needs to end with a \\n \n",
    "    f.write(header)                                                                                  #write header to file \n",
    "\n",
    "    \n",
    "    for site in tqdm(sites):\n",
    "        if site[1] <= distance_max or site[1]+distance_max >= fastas_dict[site[0]][1]:               # only use sites that will have values for site +- max distance (buffer). second element in fastas dict is the length \n",
    "            list_sites_outOfBufferRange.append(site)\n",
    "        \n",
    "        else: \n",
    "            row = []\n",
    "            row.extend([site[0], site[1]])\n",
    "            alignment = fastas_dict[site[0]][0]                                                       #create the alingment from the list of fastas \n",
    "            \n",
    "            \n",
    "            #makes the triplet depending on itf mutant or nah \n",
    "            if site[2] ==1:                                     # 1 means mut==yes, muts_by-chrom_dict is literally a dictionary containing list of sites that are mutations in that chrom. \n",
    "                mutation_row = mutations_df[(mutations_df.chrom == site[0]) & (mutations_df.pos == site[1])]  #get the row containing mut info out of the df \n",
    "\n",
    "                mutation_bp = mutation_row.alt.values[0]\n",
    "                mutated_triplet = str(alignment[0,site[1]-2]).upper()+str(mutation_bp)+str(alignment[0,site[1]]).upper() #these bounds ahve been tested \n",
    "\n",
    "                old_bp = mutation_row.ref.values[0]\n",
    "                old_triplet = str(alignment[0,site[1]-2]).upper()+str(old_bp)+str(alignment[0,site[1]]).upper() #these bounds have been tested \n",
    "\n",
    "                row.extend([old_triplet, 1])\n",
    "\n",
    "                seq_triplet = str(alignment[0,site[1]-2:site[1]+1].seq)#these bounds have been tested \n",
    "                if old_triplet.upper() != seq_triplet.upper(): \n",
    "                    alignment_discordant.append(old_triplet+\" \"+seq_triplet+\" \"+\" \"+str(mutation_row)+\" \"+str(sites.index(site))+\" \"+str(site))\n",
    "                    \n",
    "            else: \n",
    "                triplet= str(alignment[0,site[1]-2:site[1]+1].seq).upper()\n",
    "                row.extend([triplet,0])\n",
    "            \n",
    "            #converting fro 0 to nomral chrom lists so can get correct files \n",
    "#             index_chromConversion = list_chroms.index(site[0])                                        #takes the first element of site (chr from tabix) and searches for the index within the list. \n",
    "#             chrom_forFiles = list_0chroms[index_chromConversion]                                      #used the previous index to get out the ch 0 number needed for the files : chr01 \n",
    "\n",
    "            #track stuff \n",
    "            for trackname,track_val in tracksColFile_dict.items():                 \n",
    "                \n",
    "                 \n",
    "                data_col = track_val[0] \n",
    "                global_or_tissue_specific = track_val[1]\n",
    "                Na_is_0_or_NA = track_val[2]\n",
    "                filename = track_val[3] \n",
    "                    \n",
    "                for distance in list_of_surrounding_contexts: \n",
    "                    #track_output = [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]\n",
    "                    if not [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]:                #if no value at that site \n",
    "                        if Na_is_0_or_NA == \"Na=0\": \n",
    "                            row.append(0)\n",
    "                        else: \n",
    "                            row.extend([\"NA\"])                                                                                      \n",
    "\n",
    "                    else:                                                   \n",
    "                        track_output = [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]\n",
    "                        multiple_values = []\n",
    "                        if data_col == 4:\n",
    "                            for element in track_output: \n",
    "                                multiple_values.append(float(element.split()[4]))\n",
    "                            #print(multiple_values)\n",
    "                            average_value = sum(multiple_values)/len(multiple_values) \n",
    "                            row.append(average_value)\n",
    "                        elif data_col == 3: \n",
    "                            for element in track_output: \n",
    "                                multiple_values.append(float(element.split()[3]))\n",
    "                            #print(multiple_values)\n",
    "                            average_value = sum(multiple_values)/len(multiple_values) \n",
    "                            row.append(average_value)\n",
    "                        elif data_col== 'binary': \n",
    "                            row.append(len(track_output))\n",
    "                        else: \n",
    "                            print(\"ERROR: track coloumns not 4 or 3 or binary\")\n",
    "                            print(tracksColFile_dict[trackname])\n",
    "\n",
    "            #sequence stuff                \n",
    "            for distance in list_of_surrounding_contexts: \n",
    "                seq_around = str(alignment[0,site[1]-2:site[1]+1].seq)\n",
    "                if seq_around != '': \n",
    "                    seq_around = str(alignment[0,site[1]-distance-1:site[1]+distance].seq)  #chnaged from  str(alignment[0,site[1]-distance:site[1]+distance+1].seq)\n",
    "                    Acount = seq_around.count('a')+seq_around.count(\"A\")\n",
    "                    Gcount = seq_around.count('g')+seq_around.count(\"G\")\n",
    "                    Ccount = seq_around.count('c')+seq_around.count(\"C\")\n",
    "                    Tcount = seq_around.count('t')+seq_around.count(\"T\")\n",
    "                    Apercent = Acount/len(seq_around)\n",
    "                    Gpercent = Gcount/len(seq_around)\n",
    "                    Cpercent = Ccount/len(seq_around)\n",
    "                    Tpercent = Tcount/len(seq_around)\n",
    "                    row.extend([Apercent, Gpercent, Cpercent, Tpercent])\n",
    "                else: \n",
    "                    row.extend(['NA','NA','NA','NA'])\n",
    "                    list_no_seq_at_site.append(site)\n",
    "            #print(header\n",
    "            #print(row)          \n",
    "            #print(len(row))\n",
    "            row_string = str()\n",
    "            for i in range(0,len(row)): \n",
    "                row_string = row_string+str(row[i])+\"\\t\"\n",
    "            row_string = row_string.rstrip(\"\\t\")\n",
    "            row_string = row_string+\"\\n\"\n",
    "            f.write(row_string)\n",
    "print(len(list_sites_outOfBufferRange))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591bca6-0432-4fc0-a34f-0371ff298321",
   "metadata": {},
   "source": [
    "## ** 1.7 printing error output of the model ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8e7a2ef0-7f5b-4d5f-a606-3b45f98db491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "59\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(list_sites_outOfBufferRange))\n",
    "print(len(alignment_discordant))\n",
    "print(len( list_no_seq_at_site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6e3b16bf-32d7-4199-9400-13fcd738dc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"GGGTAAAG GGG        chrom        pos   fake_end     ref alt  Fathers_age_at_conception  \\\\\\n64329  chr3  104363463  104363464  GGTAAA   G                         22   \\n\\n       Mothers_age_at_conception  \\n64329                         22   4 ['chr3', 104363463, 1]\"]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_discordant[0].split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6d489a12-6e3f-4ab9-b5ae-7216505ccb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAC ctc         chrom       pos  fake_end ref alt  Fathers_age_at_conception  \\\n",
      "15648  chr11  51391842  51391843   A   G                         58   \n",
      "\n",
      "       Mothers_age_at_conception  \n",
      "15648                         37   1350 ['chr11', 51391842, 1]\n",
      "ACG AGG       chrom        pos   fake_end ref alt  Fathers_age_at_conception  \\\n",
      "4611  chr1  120696615  120696616   C   G                         32   \n",
      "\n",
      "      Mothers_age_at_conception  \n",
      "4611                         30   1527 ['chr1', 120696615, 1]\n"
     ]
    }
   ],
   "source": [
    "for line in alignment_discordant: \n",
    "    if len(line.split()[0]) == 3: \n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba0889-80d4-45ca-927a-25469a35ecd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d4f66-2cec-4dc0-a489-28ef9a470006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89456566-d1e1-4b2d-998e-7dd250ef740d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0617fe-8c9d-4b18-99d8-cd66afaa50cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318106b3-cae1-4c41-9365-35528a2cb526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ca712-8877-4503-85a7-30c16e52be67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a83619-a14f-4e25-9329-91b6e688b82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67dd90a-f92c-4e25-9a49-0e828485e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa3f71-f51f-4e9d-b09e-f280ac84db0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86003b8c-5565-4189-9088-2dfd67554f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bfce4a1-8c82-43a4-be25-71e009db2992",
   "metadata": {},
   "source": [
    "# **parallelizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7459f383-e0b8-4962-ac03-8eb958fb1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1397e18d-3270-4774-ba40-77614b59a233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "034bde53-2ac9-4e72-ace7-83119c88219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(site):\n",
    "    if site[1] <= distance_max or site[1]+distance_max >= fastas_dict[site[0]][1]:               # only use sites that will have values for site +- max distance (buffer). second element in fastas dict is the length \n",
    "            list_sites_outOfBufferRange.append(site)\n",
    "        \n",
    "    else: \n",
    "        row = []\n",
    "        row.extend([site[0], site[1]])\n",
    "        alignment = fastas_dict[site[0]][0]                                                       #create the alingment from the list of fastas \n",
    "\n",
    "\n",
    "        #makes the triplet depending on itf mutant or nah \n",
    "        if site[2] ==1:                                     # 1 means mut==yes, muts_by-chrom_dict is literally a dictionary containing list of sites that are mutations in that chrom. \n",
    "            mutation_row = mutations_df[(mutations_df.chrom == site[0]) & (mutations_df.pos == site[1])]  #get the row containing mut info out of the df \n",
    "\n",
    "            mutation_bp = mutation_row.alt.values[0]\n",
    "            mutated_triplet = str(alignment[0,site[1]-2]).upper()+str(mutation_bp)+str(alignment[0,site[1]]).upper() #these bounds ahve been tested \n",
    "\n",
    "            old_bp = mutation_row.ref.values[0]\n",
    "            old_triplet = str(alignment[0,site[1]-2]).upper()+str(old_bp)+str(alignment[0,site[1]]).upper() #these bounds have been tested \n",
    "\n",
    "            row.extend([old_triplet, 1])\n",
    "\n",
    "            seq_triplet = str(alignment[0,site[1]-2:site[1]+1].seq)#these bounds have been tested \n",
    "            if old_triplet.upper() != seq_triplet.upper(): \n",
    "                alignment_discordant.append(old_triplet+\" \"+seq_triplet+\" \"+\" \"+str(mutation_row)+\" \"+str(sites.index(site))+\" \"+str(site))\n",
    "\n",
    "        else: \n",
    "            triplet= str(alignment[0,site[1]-2:site[1]+1].seq).upper()\n",
    "            row.extend([triplet,0])\n",
    "\n",
    "        #converting fro 0 to nomral chrom lists so can get correct files \n",
    "#             index_chromConversion = list_chroms.index(site[0])                                        #takes the first element of site (chr from tabix) and searches for the index within the list. \n",
    "#             chrom_forFiles = list_0chroms[index_chromConversion]                                      #used the previous index to get out the ch 0 number needed for the files : chr01 \n",
    "\n",
    "        #track stuff \n",
    "        for trackname,track_val in tracksColFile_dict.items():                 \n",
    "\n",
    "\n",
    "            data_col = track_val[0] \n",
    "            global_or_tissue_specific = track_val[1]\n",
    "            Na_is_0_or_NA = track_val[2]\n",
    "            filename = track_val[3] \n",
    "\n",
    "            for distance in list_of_surrounding_contexts: \n",
    "                #track_output = [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]\n",
    "                if not [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]:                #if no value at that site \n",
    "                    if Na_is_0_or_NA == \"Na=0\": \n",
    "                        row.append(0)\n",
    "                    else: \n",
    "                        row.extend([\"NA\"])                                                                                      \n",
    "\n",
    "                else:                                                   \n",
    "                    track_output = [record for record in pysam.Tabixfile(filename).fetch(site[0], site[1]-distance, site[1]+distance+1)]\n",
    "                    multiple_values = []\n",
    "                    if data_col == 4:\n",
    "                        for element in track_output: \n",
    "                            multiple_values.append(float(element.split()[4]))\n",
    "                        #print(multiple_values)\n",
    "                        average_value = sum(multiple_values)/len(multiple_values) \n",
    "                        row.append(average_value)\n",
    "                    elif data_col == 3: \n",
    "                        for element in track_output: \n",
    "                            multiple_values.append(float(element.split()[3]))\n",
    "                        #print(multiple_values)\n",
    "                        average_value = sum(multiple_values)/len(multiple_values) \n",
    "                        row.append(average_value)\n",
    "                    elif data_col== 'binary': \n",
    "                        row.append(len(track_output))\n",
    "                    else: \n",
    "                        print(\"ERROR: track coloumns not 4 or 3 or binary\")\n",
    "                        print(tracksColFile_dict[trackname])\n",
    "\n",
    "        #sequence stuff                \n",
    "        for distance in list_of_surrounding_contexts: \n",
    "            seq_around = str(alignment[0,site[1]-2:site[1]+1].seq)\n",
    "            if seq_around != '': \n",
    "                seq_around = str(alignment[0,site[1]-distance-1:site[1]+distance].seq)  #chnaged from  str(alignment[0,site[1]-distance:site[1]+distance+1].seq)\n",
    "                Acount = seq_around.count('a')+seq_around.count(\"A\")\n",
    "                Gcount = seq_around.count('g')+seq_around.count(\"G\")\n",
    "                Ccount = seq_around.count('c')+seq_around.count(\"C\")\n",
    "                Tcount = seq_around.count('t')+seq_around.count(\"T\")\n",
    "                Apercent = Acount/len(seq_around)\n",
    "                Gpercent = Gcount/len(seq_around)\n",
    "                Cpercent = Ccount/len(seq_around)\n",
    "                Tpercent = Tcount/len(seq_around)\n",
    "                row.extend([Apercent, Gpercent, Cpercent, Tpercent])\n",
    "            else: \n",
    "                row.extend(['NA','NA','NA','NA'])\n",
    "                list_no_seq_at_site.append(site)\n",
    "        #print(header\n",
    "        #print(row)          \n",
    "        #print(len(row))\n",
    "        row_string = str()\n",
    "        for i in range(0,len(row)): \n",
    "            row_string = row_string+str(row[i])+\"\\t\"\n",
    "        row_string = row_string.rstrip(\"\\t\")\n",
    "        row_string = row_string+\"\\n\"\n",
    "        return row_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36ae3884-b72d-4fdb-a23a-8b256487798d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr4', 147907388, 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4b39536-8161-4245-8e1f-84f9d1042109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr21\\t1417507\\tNNN\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\tNA\\tNA\\tNA\\t0\\t0\\t0\\t0\\t0\\t0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(sites[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1dc1604-a07a-44fe-b7fb-683c4b42a3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr4\t147907388\tAAA\t1\t0.0\t0.0\t0.5417341228070175\t0.46466\t0.565276875\t0.6800353357531765\t0.0\t0.0\t0.9541180092592614\t1.0526\t1.0904975\t0.6217522914521113\t0.57553\t0.38230666666666663\t0.8276204593639565\t0.7622\t0.7014627272727272\t0.7011680098280098\t0.0\t0.0164408\t0.04055397066666665\t0.0387503\t0.0387503\t0.06004818473282444\t0\t0\t0\t0\t0\t0.013109999999999998\t0\t0\t1.1652631578947368\t1.50124\t1.50124\t1.50124\t0\t0\t2\t21.0\t21.0\t21.5\t1.0\t0.0\t0.0\t0.0\t0.35323383084577115\t0.22885572139303484\t0.10945273631840796\t0.30845771144278605\t0.3023348832558372\t0.18104094795260237\t0.17704114794260287\t0.33958302084895753\n",
      "\n",
      "chr8\t37280633\tTGT\t1\t1.52342\t1.4206990909090906\t0.826685210810809\t0.24245\t0.38473428571428575\t0.7916427525622233\t1.07802\t1.0274371428571432\t1.3322837939914152\t0.41188\t0.656560625\t1.0021615578947365\t0.34284\t0.30701222222222224\t0.6660858968347008\t0.79536\t0.5990331249999999\t0.6122181364392679\t0.0986448\t0.0904243\t0.06181737599999985\t0.0387503\t0.0387503\t0.10800925895522388\t0\t0\t0\t0\t0\t0.01311\t0\t0.287\t0.02825925925925928\t0.754738\t0.754738\t0.754738\t0\t0\t3\t5.0\t5.0\t4.5\t0.0\t1.0\t0.0\t0.0\t0.208955223880597\t0.3034825870646766\t0.22388059701492538\t0.263681592039801\t0.2727863606819659\t0.21778911054447278\t0.24258787060646966\t0.2668366581670916\n",
      "\n",
      "chr21\t1417507\tNNN\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\tNA\tNA\tNA\t0\t0\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
      "\n",
      "chr3\t5330124\tGCG\t1\t0.0\t0.0\t0.793513797814207\t1.3941\t1.4362413636363636\t0.7476666859344864\t0.0\t0.571415\t1.168912773246329\t0.5263\t0.6002356521739131\t0.7590266204690849\t0.57139\t0.916624\t0.7496957741347916\t0.19053\t0.2775206666666667\t0.6358857774390234\t0.0\t0.0\t0.08343705666666641\t0.0\t0.0\t0.22092709188311685\t0\t0\t0\t0\t0\t0\t0\t0\t0.9669285714285715\t2.65133\t2.65133\t2.65133\t0\t0\t7\t4.0\t4.0\t3.5\t0.0\t0.0\t1.0\t0.0\t0.19900497512437812\t0.24378109452736318\t0.2885572139303483\t0.26865671641791045\t0.2864356782160892\t0.22708864556772163\t0.19754012299385032\t0.2889355532223389\n",
      "\n",
      "chr14\t1271698\tNNN\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\tNA\tNA\tNA\t0\t0\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
      "\n",
      "chr3\t14723563\tCAT\t1\t0.0\t0.0\t0.8025740334855411\t0.0\t0.0\t0.6546045392021984\t0.0\t0.9378166666666666\t0.8466516426512971\t0.41008\t0.48168166666666656\t0.5658485960874583\t0.57553\t0.287765\t0.5817149555950264\t0.59397\t0.6086199999999998\t0.7019581694915262\t0.0\t0.0164408\t0.05436201005025113\t0.0387503\t0.01937515\t0.03348025999999995\t0\t0\t0.02603\t0\t0.01311\t0.014301818181818183\t0\t0\t0.6551333333333332\t1.774\t1.774\t1.774\t0\t0\t6\t4.0\t4.0\t3.5\t1.0\t0.0\t0.0\t0.0\t0.24875621890547264\t0.30845771144278605\t0.23383084577114427\t0.208955223880597\t0.24468776561171943\t0.21343932803359833\t0.22483875806209688\t0.31703414829258536\n",
      "\n",
      "chr3\t83677251\tCAC\t0\t0.0\t0.36804\t0.6277775728155338\t0.75914\t0.4870842857142857\t0.7621891717791379\t0.53908\t0.9814366666666666\t0.9619090862944184\t0.28665\t0.3826014285714286\t0.6582862589459948\t0.57139\t0.38230666666666663\t0.7297378661087863\t0.62266\t0.7840755555555556\t0.7948195245641834\t0.0\t0.0328816\t0.0438421157232704\t0.0\t0.0\t0.037610589705882325\t0\t0\t0.02603\t0\t0\t0.01311\t0\t0\t0.604153846153846\t0.220173\t0.220173\t0.220173\t0\t0\t1\t3.0\t3.0\t4.0\t1.0\t0.0\t0.0\t0.0\t0.20398009950248755\t0.21393034825870647\t0.30845771144278605\t0.2736318407960199\t0.2791860406979651\t0.1831908404579771\t0.17589120543972803\t0.3617319134043298\n",
      "\n",
      "chr3\t14732767\tGAA\t0\t0.0\t0.26052\t1.631858929110105\t0.33795\t0.320405\t0.6853510460526301\t0.0\t1.0478539999999998\t1.9867654646840145\t0.66983\t0.689588076923077\t0.7059435503560519\t0.57553\t0.5754833333333332\t0.6773596779661011\t0.69298\t0.8055476\t0.675272532552083\t0.0986448\t0.08549208\t0.06405947564766834\t0.0387503\t0.012916766666666668\t0.09687576722222221\t0\t0\t0.026030000000000005\t0\t0\t0.014301818181818183\t0\t0\t0.5845\t1.774\t1.774\t1.774\t0\t0\t8\t3.0\t3.0\t3.5\t1.0\t0.0\t0.0\t0.0\t0.3781094527363184\t0.25870646766169153\t0.1890547263681592\t0.17412935323383086\t0.2545872706364682\t0.21338933053347334\t0.20613969301534923\t0.32588370581470927\n",
      "\n",
      "chr2\t157248415\tGGC\t1\t0.58308\t0.77744\t0.9421694897959181\t0.38458\t0.38781749999999987\t0.6599858220640543\t0.9379\t0.9378375\t1.7502710059171604\t0.65338\t0.6061895652173913\t0.7872152733964253\t2.30198\t1.8908657142857141\t0.9061313595166165\t0.47311\t0.35523222222222217\t0.95879550591327\t0.0328816\t0.024661199999999998\t0.05750524018264829\t0.0\t0.0\t0.07064973370165756\t0\t0\t0.02603\t0\t0\t0.013110000000000002\t3.404\t3.404\t1.068272727272727\t0.830349\t0.830349\t0.830349\t0\t0\t1\t4.0\t4.0\t3.6666666666666665\t0.0\t1.0\t0.0\t0.0\t0.30845771144278605\t0.21393034825870647\t0.1890547263681592\t0.2885572139303483\t0.3055847207639618\t0.1832408379581021\t0.17624118794060298\t0.33493325333733315\n",
      "\n",
      "chr1\t133566363\tNNN\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\tNA\tNA\tNA\t0\t0\t0\t0\t0\t0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for site in sites[0:10]:\n",
    "    print(f(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3489fc2-7aee-45ff-9d35-9053214f0d12",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/omanmade/.conda/envs/mutability/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/omanmade/.conda/envs/mutability/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_26789/3427143967.py\", line 2, in f\n    if site[1] <= distance_max or site[1]+distance_max >= fastas_dict[site[0]][1]:               # only use sites that will have values for site +- max distance (buffer). second element in fastas dict is the length\nTypeError: '<=' not supported between instances of 'list' and 'int'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26789/1728340842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msites\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/mutability/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mutability/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# def f(x):\n",
    "#     return x \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [sites[0:10]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mutability] *",
   "language": "python",
   "name": "conda-env-.conda-mutability-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
